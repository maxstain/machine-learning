{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. The library imports",
   "id": "42c1abf53b57ddc5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T07:29:25.930090Z",
     "start_time": "2025-04-16T07:29:25.915663Z"
    }
   },
   "source": [
    "from flask import Flask, request, render_template, get_flashed_messages\n",
    "from models.ml_model import MLModel\n",
    "from utils.data_verification import verify_data_structure\n",
    "import pandas as pd\n",
    "import logging"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Dataset cleaning",
   "id": "579c85eb12c42e6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:29:29.748455Z",
     "start_time": "2025-04-16T07:29:29.722209Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "mdl = MLModel()\n",
    "df = mdl.clean_dataset(mdl.process_dataset())\n",
    "print(df)"
   ],
   "id": "f28aa176c1618726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T08:39:45.450579Z",
     "start_time": "2025-04-16T08:39:45.390194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not verify_data_structure():\n",
    "    logging.error(\"Data structure verification failed.\")\n",
    "else:\n",
    "    logging.info(\"Data structure verification passed.\")"
   ],
   "id": "1248d567c4fe42fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data structure verification passed.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3.Train the model",
   "id": "c9425d3da380a09f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T08:42:54.407941Z",
     "start_time": "2025-04-16T08:42:53.896744Z"
    }
   },
   "cell_type": "code",
   "source": "mdl.train_model(df)",
   "id": "b651708ff44bc8e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4.Get the dummy data",
   "id": "caba27a941f25b35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T08:54:15.660452Z",
     "start_time": "2025-04-16T08:54:11.190166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Your input data\n",
    "input_data = pd.DataFrame({'agency_type': [\"Airlines\"]})\n",
    "\n",
    "# The column names in your training data seem to have used underscores\n",
    "# and different capitalization. Let's modify the input column name first\n",
    "input_data.columns = ['Agency Type']  # Match the original column name\n",
    "\n",
    "# Get dummies with a prefix separator that matches your training data\n",
    "input_encoded = pd.get_dummies(input_data, prefix_sep='_')\n",
    "\n",
    "# Make sure all expected columns exist\n",
    "for col in mdl.feature_names:\n",
    "    if col not in input_encoded.columns:\n",
    "        input_encoded[col] = 0\n",
    "\n",
    "# Ensure we use only the features the model knows about, in the right order\n",
    "prediction = mdl.model.predict(input_encoded[mdl.feature_names])\n",
    "result = mdl.label_encoder.inverse_transform(prediction)[0]"
   ],
   "id": "2cc1378e132c6f1e",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Agency\n- Agency Type\nFeature names seen at fit time, yet now missing:\n- Agency Type_Airlines\n- Agency Type_Travel Agency\n- Agency_ADM\n- Agency_ART\n- Agency_C2B\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m prediction = \u001B[43mmdl\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_encoded\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmdl\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m result = mdl.label_encoder.inverse_transform(prediction)[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Projects\\Python\\Machine Learning\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001B[39m, in \u001B[36mForestClassifier.predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    883\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[32m    884\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    885\u001B[39m \u001B[33;03m    Predict class for X.\u001B[39;00m\n\u001B[32m    886\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    902\u001B[39m \u001B[33;03m        The predicted classes.\u001B[39;00m\n\u001B[32m    903\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m904\u001B[39m     proba = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    906\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_outputs_ == \u001B[32m1\u001B[39m:\n\u001B[32m    907\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.classes_.take(np.argmax(proba, axis=\u001B[32m1\u001B[39m), axis=\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Projects\\Python\\Machine Learning\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001B[39m, in \u001B[36mForestClassifier.predict_proba\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    944\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    945\u001B[39m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m946\u001B[39m X = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    948\u001B[39m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[32m    949\u001B[39m n_jobs, _, _ = _partition_estimators(\u001B[38;5;28mself\u001B[39m.n_estimators, \u001B[38;5;28mself\u001B[39m.n_jobs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Projects\\Python\\Machine Learning\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001B[39m, in \u001B[36mBaseForest._validate_X_predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    635\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    636\u001B[39m     ensure_all_finite = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m638\u001B[39m X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    639\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    640\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    641\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    642\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    643\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    644\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    645\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    646\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X.indices.dtype != np.intc \u001B[38;5;129;01mor\u001B[39;00m X.indptr.dtype != np.intc):\n\u001B[32m    647\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Projects\\Python\\Machine Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2835\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mvalidate_data\u001B[39m(\n\u001B[32m   2836\u001B[39m     _estimator,\n\u001B[32m   2837\u001B[39m     /,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2843\u001B[39m     **check_params,\n\u001B[32m   2844\u001B[39m ):\n\u001B[32m   2845\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001B[39;00m\n\u001B[32m   2846\u001B[39m \n\u001B[32m   2847\u001B[39m \u001B[33;03m    This helper function should be used in an estimator that requires input\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2917\u001B[39m \u001B[33;03m        validated.\u001B[39;00m\n\u001B[32m   2918\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2919\u001B[39m     \u001B[43m_check_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2920\u001B[39m     tags = get_tags(_estimator)\n\u001B[32m   2921\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m tags.target_tags.required:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Projects\\Python\\Machine Learning\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001B[39m, in \u001B[36m_check_feature_names\u001B[39m\u001B[34m(estimator, X, reset)\u001B[39m\n\u001B[32m   2774\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[32m   2775\u001B[39m     message += \u001B[33m\"\u001B[39m\u001B[33mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m2777\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[31mValueError\u001B[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Agency\n- Agency Type\nFeature names seen at fit time, yet now missing:\n- Agency Type_Airlines\n- Agency Type_Travel Agency\n- Agency_ADM\n- Agency_ART\n- Agency_C2B\n- ...\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
